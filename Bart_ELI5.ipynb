{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parrot-qa.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rIaN3HCVU4p4"
      ],
      "authorship_tag": "ABX9TyNjhA/nOiTyEaB8x/DBsK75",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parrot-qa/models/blob/main/Bart_ELI5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-requisites\n",
        "\n",
        "Upload the train, dev and test files as generated by the DPR script:\n",
        "- `parrot-qa-ctx-train.json`\n",
        "- `parrot-qa-ctx-dev.json`\n",
        "- `parrot-qa-ctx-test.json`\n",
        "\n"
      ],
      "metadata": {
        "id": "rIaN3HCVU4p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sentencepiece rouge_score"
      ],
      "metadata": {
        "id": "LPTcVQWm_AMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: BART Fine-tuning"
      ],
      "metadata": {
        "id": "1EDFF3bH_7eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform fine-tuning or run zero-shot?\n",
        "DO_FINE_TUNING = True\n",
        "\n",
        "# For training with mini-batches, TOKENIZER_BATCH_SIZE must be 2048\n",
        "# For training one sample at a time, TOKENIZER_BATCH_SIZE should be small, e.g. 16\n",
        "TOKENIZER_BATCH_SIZE = 16\n",
        "TRAIN_BATCH_SIZE = 1\n",
        "EVAL_BATCH_SIZE = 1\n",
        "\n",
        "# When tokenizing text\n",
        "MAX_QUES_CTX_LENGTH = 1024\n",
        "MAX_ANS_LENGTH = 512\n",
        "\n",
        "MODEL_NAME = 'yjernite/bart_eli5'\n",
        "DEVICE = 'cuda'"
      ],
      "metadata": {
        "id": "mirRSWc9TMoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reformat dataset"
      ],
      "metadata": {
        "id": "pZnx2ldQRkOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "def create_dataset(file_path):\n",
        "    with open(file_path) as fp:\n",
        "        dataset = json.load(fp)\n",
        "    \n",
        "    q, a, c = [], [], []\n",
        "    for item in dataset:\n",
        "        q.append(item['question'])\n",
        "        a.append(item['answer'])\n",
        "        c.append(' '.join(item['contexts']))\n",
        "    \n",
        "    data = {'question': q, 'answer': a, 'context': c}\n",
        "    return Dataset.from_dict(data)\n",
        "\n",
        "\n",
        "train = create_dataset('parrot-qa-ctx-train.json')\n",
        "dev = create_dataset('parrot-qa-ctx-dev.json')\n",
        "test = create_dataset('parrot-qa-ctx-test.json')\n",
        "\n",
        "len(train), len(dev), len(test)"
      ],
      "metadata": {
        "id": "58bcKze48OEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and perform tokenization"
      ],
      "metadata": {
        "id": "Zb8SToBoS0FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
      ],
      "metadata": {
        "id": "RugwV2igDupZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_all(samples):\n",
        "    q, c, a = samples['question'], samples['context'], samples['answer']\n",
        "    qc = [f'question: {qval} context: {cval}' for (qval, cval) in zip(q, c)]\n",
        "    inp = tokenizer(qc, padding=True, truncation=True, max_length=MAX_QUES_CTX_LENGTH)\n",
        "    outp = tokenizer(a, padding=True, truncation=True, max_length=MAX_ANS_LENGTH)\n",
        "    return {\n",
        "        'input_ids': inp.input_ids,\n",
        "        'attention_mask': inp.attention_mask,\n",
        "        'labels': outp.input_ids,\n",
        "        'decoder_attention_mask': outp.attention_mask\n",
        "    }\n",
        "\n",
        "\n",
        "train = train.map(tokenize_all, batched=True, batch_size=TOKENIZER_BATCH_SIZE)\n",
        "dev = dev.map(tokenize_all, batched=True, batch_size=TOKENIZER_BATCH_SIZE)\n",
        "test = test.map(tokenize_all, batched=True, batch_size=TOKENIZER_BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ksmk9Ow8S_vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "X1c8--GrTwqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(DEVICE)\n"
      ],
      "metadata": {
        "id": "cCacoD09T0lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    'output',\n",
        "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    load_best_model_at_end=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    predict_with_generate=True,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train,\n",
        "    eval_dataset=dev,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "if DO_FINE_TUNING:\n",
        "    trainer.train()"
      ],
      "metadata": {
        "id": "ZE-5SGhAD9F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform inference"
      ],
      "metadata": {
        "id": "TvWWe1b8T756"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "\n",
        "def calc_rouge(dataset):\n",
        "    pred = trainer.predict(dataset)\n",
        "    pred_answers = tokenizer.batch_decode(pred.predictions, skip_special_tokens=True)\n",
        "    results = rouge.compute(predictions=pred_answers, references=dataset['answer'])\n",
        "    return results\n",
        "\n",
        "\n",
        "train_rouge = calc_rouge(train)\n",
        "dev_rouge = calc_rouge(dev)\n",
        "test_rouge = calc_rouge(test)"
      ],
      "metadata": {
        "id": "CbVGIWBhT9q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_rouge(split, score):\n",
        "    R1 = score['rouge1'].mid.fmeasure * 100\n",
        "    R2 = score['rouge2'].mid.fmeasure * 100\n",
        "    RL = score['rougeL'].mid.fmeasure * 100\n",
        "    print(f'{split}: R1 = {R1:.2f}, R2 = {R2:.2f}, RL = {RL:.2f}')\n",
        "\n",
        "\n",
        "display_rouge('Train', train_rouge)\n",
        "display_rouge('Dev', dev_rouge)\n",
        "display_rouge('Test', test_rouge)"
      ],
      "metadata": {
        "id": "-Qa3gYwJ47-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}